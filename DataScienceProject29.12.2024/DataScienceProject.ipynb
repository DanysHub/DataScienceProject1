{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Organisatorisches: Projekt mit schriftlicher Ausarbeitung</h1>\n",
    "\n",
    "4. Gruppe:\n",
    "Thema: Diamond Price Prediction\n",
    "Vortragstag: 8.1.2025\n",
    "Mitglieder: Nahid Qazi, Mohaddese Haydari, Azad Akin, Sean Müller, Denis Meyendrisch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Analyseziel:\n",
    "\n",
    "- Prognose des Diamantenpreises basierend auf den verfügbaren Merkmalen.  \n",
    "- Untersuchung der wichtigsten Einflussfaktoren (z.B. Karat, Schliff, Farbe, Reinheit) auf den Preis.  \n",
    "- Modellierung und Evaluierung der Vorhersagegenauigkeit von mindestens zwei verschiedenen Machine-Learning-Modellen.  \n",
    "- Visualisierung von Beziehungen und Verteilungen der Merkmale und ihrer Korrelation zum Preis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Kurze Beschreibung der Daten und der Datenqualität\n",
    "\n",
    "Der vorliegende Datensatz enthält Informationen zu verschiedenen Eigenschaften von Diamanten, die für die Vorhersage ihres Preises verwendet werden. Jedes Datensatzobjekt beschreibt einen einzelnen Diamanten anhand der folgenden Merkmale:\n",
    "\n",
    "- **Carat (Karat)**: Das Gewicht des Diamanten, ein wichtiger Faktor für den Preis.\n",
    "- **Cut (Schliff)**: Die Qualität des Schliffs des Diamanten, unterteilt in verschiedene Kategorien wie \"Ideal\", \"Premium\", \"Good\", \"Very Good\" und \"Fair\".\n",
    "- **Color (Farbe)**: Die Farbqualität des Diamanten, bewertet mit einer Skala von D (bestes Weiß) bis Z (farbiger Diamant).\n",
    "- **Clarity (Reinheit)**: Die Reinheit des Diamanten, die die Anzahl und Sichtbarkeit von Einschlüsse und Unregelmäßigkeiten beschreibt, mit verschiedenen Kategorien wie \"VVS1\", \"VS2\", \"SI1\", \"SI2\", \"I1\".\n",
    "- **Depth (Tiefe)**: Die Tiefe des Diamanten in Prozent.\n",
    "- **Table (Tabelle)**: Der Anteil der oberen Fläche des Diamanten im Verhältnis zum Durchmesser.\n",
    "- **Price (Preis)**: Der Marktpreis des Diamanten, der als Zielvariable für die Vorhersage dient.\n",
    "- **x, y, z**: Die physikalischen Dimensionen des Diamanten (Länge, Breite, Höhe in Millimetern).\n",
    "\n",
    "Die Daten sind von guter Qualität, da es **keine fehlenden Werte** gibt. Alle Werte sind vollständig und es gibt keine offensichtlichen Inkonsistenzen oder fehlerhaften Einträge. Allerdings sollten die numerischen Merkmale wie `carat`, `depth`, `table` und `price` einer weiteren Überprüfung auf Ausreißer unterzogen werden, um sicherzustellen, dass diese Werte in einem angemessenen Bereich liegen und keine Fehler vorliegen. Kategorische Variablen wie `cut`, `color` und `clarity` wurden bereits in einem standardisierten Format vorverarbeitet.\n",
    "\n",
    "Insgesamt weist der Datensatz keine fehlenden oder ungültigen Daten auf, was eine gute Grundlage für die Durchführung von Modellierung und Vorhersagen bietet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Import der erforderlichen Module und des Datensatzes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, MinMaxScaler\n",
    "\n",
    "# Get the directory where the current notebook is located\n",
    "notebook_dir = os.path.dirname(os.path.abspath(\"__file__\"))\n",
    "\n",
    "# Define the relative path to the dataset\n",
    "dataset_path = os.path.join(notebook_dir, 'Datasets', 'Diamonds.csv')\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(dataset_path, sep=',', index_col=0)\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1 Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cut'] = df['cut'].str.title()\n",
    "df['color'] = df['color'].str.upper()\n",
    "df['clarity'] = df['clarity'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot für Ausreißer\n",
    "df.boxplot(column=['price'], figsize=(6, 4))\n",
    "plt.title(\"Ausreißerprüfung für Preis\")\n",
    "plt.show()\n",
    "\n",
    "df.boxplot(column=['carat'], figsize=(6, 4))\n",
    "plt.title(\"Ausreißerprüfung für Carat\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kopie von der Originaldatei erstellen, bevor man was drauf speichert/ändert\n",
    "df_cleaned = df.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IQR-Methode zur Entfernung von Ausreißern\n",
    "Q1 = df['price'].quantile(0.25)\n",
    "Q3 = df['price'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Grenzen definieren\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Entferne Ausreißer\n",
    "df_cleaned = df[(df['price'] >= lower_bound) & (df['price'] <= upper_bound)]\n",
    "\n",
    "# Zeilenanzahl vor und nach der Bereinigung\n",
    "print(\"Anzahl der Zeilen vor der Bereinigung:\", len(df))\n",
    "print(\"Anzahl der Zeilen nach der Bereinigung:\", len(df_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.boxplot(column=['price'], by='cut', figsize=(6, 4))\n",
    "plt.title(\"Bereinigter Preis pro 'cut'\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere den Pfad zum Ordner \"Datasets\"\n",
    "datasets_folder = os.path.join(os.getcwd(), \"Datasets\")\n",
    "\n",
    "# Speichern des bereinigten Datensatzes im Ordner \"Datasets\"\n",
    "df_cleaned.to_csv(os.path.join(datasets_folder, \"diamonds_cleaned.csv\"), index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2 Missing Value Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-> keine Imputation nötig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. EDA\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Feature Verteilungen, Korrelationen, Visualisierungen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategorische Werte analysieren\n",
    "CategorialFeatures = [\"cut\", \"color\", \"clarity\"]\n",
    "\n",
    "# Häufigkeiten analysieren\n",
    "for feature in CategorialFeatures:\n",
    "    print(f\"Häufigkeit für {feature}:\")\n",
    "    value_counts = df[feature].value_counts()\n",
    "\n",
    "    # Formatierte Ausgabe\n",
    "    styled_counts = value_counts.to_frame(name=\"Anzahl\").style.highlight_max(axis=0, color=\"lightgreen\").highlight_min(axis=0, color=\"lightcoral\")\n",
    "    display(styled_counts)  # Anzeige in Jupyter-Notebook\n",
    "\n",
    "    # Kategorische Werte visuell darstellen mit Barplots\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.countplot(data=df, x=feature, palette=\"coolwarm\")\n",
    "    plt.title(f\"Häufigkeit der Kategorien in '{feature}'\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Häufigkeiten für kategorische Werte\n",
    "CategorialFeatures = [\"cut\", \"color\", \"clarity\"]\n",
    "for feature in CategorialFeatures:\n",
    "    print(f\"Häufigkeit für {feature}:\")\n",
    "    value_counts = df[feature].value_counts()\n",
    "\n",
    "    # Formatierte Ausgabe\n",
    "    styled_counts = value_counts.to_frame(name=\"Anzahl\").style.highlight_max(axis=0, color=\"lightgreen\").highlight_min(axis=0, color=\"lightcoral\")\n",
    "    display(styled_counts)  # Anzeige in Jupyter-Notebook\n",
    "\n",
    "    # Balkendiagramme für kategorische Werte\n",
    "    df[feature].value_counts().plot(kind='bar', figsize=(5, 3), title=f\"Häufigkeit von '{feature}'\", color='skyblue', edgecolor='black')\n",
    "    plt.xlabel(feature.capitalize())\n",
    "    plt.ylabel(\"Anzahl\")\n",
    "    plt.xticks(rotation=0)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der numerischen Features\n",
    "QuantitativeFeatures = ['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
    "\n",
    "# Histogramm -> hier ist Rice-Regel von Vorteil für jedes numerische Feature\n",
    "for feature in QuantitativeFeatures:\n",
    "    df[feature].hist(bins=\"rice\", figsize=(5, 3))\n",
    "    plt.title(f\"Verteilung von '{feature}' (Rice-Regel)\")\n",
    "    plt.xlabel(feature)\n",
    "    plt.ylabel(\"Anzahl\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistische Zusammenfassung für numerische Features\n",
    "QuantitativeFeatures = [\"carat\", \"depth\", \"table\", \"price\", \"x\", \"y\", \"z\"]\n",
    "summary_stats = df[QuantitativeFeatures].describe()\n",
    "\n",
    "# Stilvolle Ausgabe\n",
    "styled_summary = summary_stats.style.format(precision=2).highlight_max(axis=0, color=\"lightgreen\").highlight_min(axis=0, color=\"lightcoral\")\n",
    "display(styled_summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kategorische Features miteinander vergleichen\n",
    "# Kreuztabellen für Kategorische Features\n",
    "crosstab_cut_color = pd.crosstab(df['cut'], df['color'])\n",
    "crosstab_cut_clarity = pd.crosstab(df['cut'], df['clarity'])\n",
    "crosstab_color_clarity = pd.crosstab(df['color'], df['clarity'])\n",
    "\n",
    "print(\"Kreuztabelle zwischen 'cut' und 'color':\\n\", crosstab_cut_color)\n",
    "print(\"\\nKreuztabelle zwischen 'cut' und 'clarity':\\n\", crosstab_cut_clarity)\n",
    "print(\"\\nKreuztabelle zwischen 'color' und 'clarity':\\n\", crosstab_color_clarity)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gestapeltes Balkendiagramm für Cut und Color\n",
    "crosstab_cut_color.plot(kind='bar', stacked=True, figsize=(8, 5))\n",
    "plt.title(\"Korrelation zwischen 'cut' und 'color'\")\n",
    "plt.xlabel(\"Cut\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.legend(title=\"Color\")\n",
    "plt.show()\n",
    "\n",
    "# Gestapeltes Balkendiagramm für Cut und Clarity\n",
    "crosstab_cut_clarity.plot(kind='bar', stacked=True, figsize=(8, 5))\n",
    "plt.title(\"Korrelation zwischen 'cut' und 'clarity'\")\n",
    "plt.xlabel(\"Cut\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.legend(title=\"Clarity\")\n",
    "plt.show()\n",
    "\n",
    "# Gestapeltes Balkendiagramm für Color und Clarity\n",
    "crosstab_color_clarity.plot(kind='bar', stacked=True, figsize=(8, 5))\n",
    "plt.title(\"Korrelation zwischen 'color' und 'clarity'\")\n",
    "plt.xlabel(\"Color\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.legend(title=\"Clarity\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definiere den Pfad zum Ordner \"Datasets\"\n",
    "datasets_folder = os.path.join(os.getcwd(), \"Datasets\")\n",
    "\n",
    "crosstab_cut_color.to_csv(os.path.join(datasets_folder, \"cut_vs_color.csv\"))\n",
    "crosstab_cut_clarity.to_csv(os.path.join(datasets_folder, \"cut_vs_clarity.csv\"))\n",
    "crosstab_color_clarity.to_csv(os.path.join(datasets_folder, \"color_vs_clarity.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantitative Werte mit Quantitativen Werten vergleichen (Scatterplots)\n",
    "QuantitativeFeatures = ['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
    "\n",
    "for i, feature_x in enumerate(QuantitativeFeatures):\n",
    "    for j, feature_y in enumerate(QuantitativeFeatures):\n",
    "        if i < j:  # Vermeidung von doppelten Kombinationen\n",
    "            df.plot.scatter(x=feature_x, y=feature_y, figsize=(6, 4))\n",
    "            plt.title(f\"{feature_x} vs. {feature_y}\")\n",
    "            plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrelationstabelle für numerische Features -> Wie hängen numerische Features miteinander zusammen\n",
    "# Werte zwischen -1 und +1: \n",
    "# +1: Starke positive Korrelation (beide Werte steigen gemeinsam).\n",
    "# -1: Starke negative Korrelation (ein Wert steigt, der andere sinkt).\n",
    "# 0: Keine lineare Korrelation.\n",
    "# Korrelationstabelle für numerische Features\n",
    "QuantitativeFeatures = df.select_dtypes(include=['float64', 'int64'])\n",
    "\n",
    "# Korrelationstabelle berechnen\n",
    "correlation_matrix = QuantitativeFeatures.corr(method='pearson')\n",
    "print(\"Korrelationstabelle:\\n\", correlation_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter-Matrix für alle quantitativen Features\n",
    "QuantitativeFeatures = ['carat', 'depth', 'table', 'price', 'x', 'y', 'z']\n",
    "\n",
    "scatter_matrix(df[QuantitativeFeatures], figsize=(8, 8), diagonal='hist')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenfassung der Preisdaten pro `cut`\n",
    "print(df.groupby('cut')['price'].describe())\n",
    "\n",
    "# Zusammenfassung der Preisdaten pro `color`\n",
    "print(df.groupby('color')['price'].describe())\n",
    "\n",
    "# Zusammenfassung der Preisdaten pro `clarity`\n",
    "print(df.groupby('clarity')['price'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Boxplot für Preis pro `cut`\n",
    "df.boxplot(column=['price'], by='cut', figsize=(6, 4))\n",
    "plt.title(\"Preisverteilung pro 'cut'\")\n",
    "plt.suptitle(\"\")  # Entfernt den Standardtitel\n",
    "plt.xlabel(\"Cut\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot für Preis pro `color`\n",
    "df.boxplot(column=['price'], by='color', figsize=(6, 4))\n",
    "plt.title(\"Preisverteilung pro 'color'\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Color\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot für Preis pro `clarity`\n",
    "df.boxplot(column=['price'], by='clarity', figsize=(6, 4))\n",
    "plt.title(\"Preisverteilung pro 'clarity'\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Clarity\")\n",
    "plt.ylabel(\"Price\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Boxplot für `carat` vs. `cut`\n",
    "plt.figure(figsize=(6, 4))\n",
    "df.boxplot(column=['carat'], by='cut')\n",
    "plt.title(\"Karatverteilung pro 'cut'\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Cut\")\n",
    "plt.ylabel(\"Carat\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot für `carat` vs. `color`\n",
    "plt.figure(figsize=(6, 4))\n",
    "df.boxplot(column=['carat'], by='color')\n",
    "plt.title(\"Karatverteilung pro 'color'\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Color\")\n",
    "plt.ylabel(\"Carat\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot für `carat` vs. `clarity`\n",
    "plt.figure(figsize=(6, 4))\n",
    "df.boxplot(column=['carat'], by='clarity')\n",
    "plt.title(\"Karatverteilung pro 'clarity'\")\n",
    "plt.suptitle(\"\")\n",
    "plt.xlabel(\"Clarity\")\n",
    "plt.ylabel(\"Carat\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Barplot für `cut`\n",
    "sns.countplot(data=df, x='cut')\n",
    "plt.title(\"Häufigkeit der Kategorien in 'cut'\")\n",
    "plt.show()\n",
    "\n",
    "# Boxplot für Preis pro `cut`\n",
    "sns.boxplot(data=df, x='cut', y='price')\n",
    "plt.title(\"Preisverteilung pro 'cut'\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Feature Engeneering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"cut\"].unique())\n",
    "print(df['clarity'].unique())\n",
    "print(df['color'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut_categories = ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal']\n",
    "color_categories = ['J', 'I', 'H', 'G', 'F', 'E', 'D']\n",
    "clarity_categories = ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF']\n",
    "\n",
    "encoder = OrdinalEncoder(categories=[cut_categories, clarity_categories, color_categories])\n",
    "\n",
    "ordinal_encoded = encoder.fit_transform(df[['cut', 'clarity', 'color']])\n",
    "\n",
    "\n",
    "ordinal_encoded_df = pd.DataFrame(ordinal_encoded, columns = encoder.get_feature_names_out(['cut','clarity', 'color']))\n",
    "print(ordinal_encoded_df.head())\n",
    "\n",
    "\n",
    "df_ordinal_encoded = pd.concat([df.drop(['cut', 'clarity', 'color'], axis=1), ordinal_encoded_df], axis=1)\n",
    "df = df_ordinal_encoded\n",
    "df.head(12)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price_per_carat'] = df['price'] / df['carat']\n",
    "df['volume'] = df['x'] * df['y'] * df['z']\n",
    "df['form_factor'] = df['x'] / df['y']\n",
    "df['price_to_volume'] = df['price'] / df['volume']\n",
    "df['mean_dimension'] = (df['x'] + df['y'] + df['z']) / 3\n",
    "df['table_to_depth_ratio'] = df['table'] / df['depth']\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m correlation_matrix \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mcorr()\n\u001b[0;32m      3\u001b[0m plt\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m10\u001b[39m))\n\u001b[0;32m      4\u001b[0m sns\u001b[38;5;241m.\u001b[39mheatmap(correlation_matrix, annot\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcoolwarm\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "correlation_matrix = df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm')\n",
    "plt.show()\n",
    "\n",
    "corr_with_target = correlation_matrix['price'].abs()\n",
    "threshold = 0.1\n",
    "selected_features = corr_with_target[corr_with_target > threshold].index.tolist()\n",
    "\n",
    "df_selected = df[selected_features]\n",
    "df_selected.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selected = df_selected.drop(columns=['Unnamed: 0'], errors='ignore') #unnamed wird entfernt\n",
    "df= df_selected\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y= df['price']                                                                                              #daten wurden in features x und zielwert y sowie in Trainings- und Testsets aufgeteilt \n",
    "X= df.drop(columns=['price'])\n",
    "\n",
    "X_train, X_test, y_test, y_train = train_test_split(X,y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Überprüfe die Daten auf fehlende Werte\n",
    "print(\"Anzahl fehlender Werte in den Features:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Entferne Zeilen mit fehlenden Werten\n",
    "df = df.dropna()\n",
    "\n",
    "# Überprüfe die Daten auf nicht-numerische Werte\n",
    "print(\"Datentypen der Features:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Initialisiere den StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ersetze unendliche Werte durch NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Überprüfe auf unendliche Werte\n",
    "print(\"Anzahl unendlicher Werte in den Features:\")\n",
    "print(df.isin([np.inf, -np.inf]).sum())\n",
    "\n",
    "# Entferne Zeilen mit NaN-Werten\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Überprüfe die Daten auf nicht-numerische Werte\n",
    "print(\"Datentypen der Features:\")\n",
    "print(df.dtypes)\n",
    "\n",
    "# Initialisiere den StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Auswahl der Features und Zielwert\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Fitte und transformiere die Daten\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Neuer DataFrame mit den skalierten Daten\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "df_scaled['price'] = y\n",
    "\n",
    "# Zeige die ersten Zeilen des neuen DataFrames\n",
    "print(\"Erste Zeilen des skalierten DataFrames:\")\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Ersetze unendliche Werte durch NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Überprüfe auf unendliche Werte\n",
    "print(\"Anzahl unendlicher Werte in den Features:\")\n",
    "print(df.isin([np.inf, -np.inf]).sum())\n",
    "\n",
    "# Entferne Zeilen mit NaN-Werten\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Überprüfe auf extreme Werte\n",
    "print(\"Maximale Werte in den Features:\")\n",
    "print(df.max())\n",
    "\n",
    "print(\"Minimale Werte in den Features:\")\n",
    "print(df.min())\n",
    "\n",
    "# Korrigiere extreme Werte\n",
    "extreme_cols = ['price_to_volume', 'table_to_depth_ratio']\n",
    "for col in extreme_cols:\n",
    "    median = df[col].median()\n",
    "    df[col] = np.where(np.abs(df[col]) > 1e10, median, df[col])\n",
    "\n",
    "# Initialisiere den StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Auswahl der Features und Zielwert\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Fitte und transformiere die Daten\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Neuer DataFrame mit den skalierten Daten\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "df_scaled['price'] = y\n",
    "\n",
    "# Zeige die ersten Zeilen des neuen DataFrames\n",
    "print(\"Erste Zeilen des skalierten DataFrames:\")\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Ersetze unendliche Werte durch NaN\n",
    "df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Überprüfe auf unendliche Werte\n",
    "print(\"Anzahl unendlicher Werte in den Features:\")\n",
    "print(df.isin([np.inf, -np.inf]).sum())\n",
    "\n",
    "# Entferne Zeilen mit NaN-Werten\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Überprüfe auf extreme Werte\n",
    "print(\"Maximale Werte in den Features:\")\n",
    "print(df.max())\n",
    "\n",
    "print(\"Minimale Werte in den Features:\")\n",
    "print(df.min())\n",
    "\n",
    "# Korrigiere extreme Werte\n",
    "extreme_cols = ['price_to_volume', 'table_to_depth_ratio']\n",
    "for col in extreme_cols:\n",
    "    max_value = df[col].max()\n",
    "    min_value = df[col].min()\n",
    "    print(f\"Max value for {col}: {max_value}\")\n",
    "    print(f\"Min value for {col}: {min_value}\")\n",
    "    df[col] = np.where(df[col] > 1e4, 1e4, df[col])  # Clipping extreme high values\n",
    "    df[col] = np.where(df[col] < -1e4, -1e4, df[col])  # Clipping extreme low values\n",
    "\n",
    "# Initialisiere den StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Auswahl der Features und Zielwert\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "# Fitte und transformiere die Daten\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Neuer DataFrame mit den skalierten Daten\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "df_scaled['price'] = y\n",
    "\n",
    "# Zeige die ersten Zeilen des neuen DataFrames\n",
    "print(\"Erste Zeilen des skalierten DataFrames:\")\n",
    "print(df_scaled.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten skalieren mit Standardization\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "df_scaled['price'] = y\n",
    "\n",
    "print(\"Erste Zeilen des skalierten DataFrames:\")\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten Skalieren mit Minmax scaling \n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "X = df.drop('price', axis=1)\n",
    "y = df['price']\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "df_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "df_scaled['price'] = y\n",
    "\n",
    "print(\"Erste Zeilen des skalierten DataFrames:\")\n",
    "df_scaled.head()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
